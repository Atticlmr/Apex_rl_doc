<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="apexrl.optimizers.muon module" href="apexrl.optimizers.muon.html"><link rel="prev" title="apexrl.models.mlp module" href="apexrl.models.mlp.html">

    <!-- Generated with Sphinx 9.1.0 and Furo 2025.12.19 -->
        <title>apexrl.optimizers package - ApexRL 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=edbbb9d3" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  --color-brand-primary: #2563eb;
  --color-brand-content: #2563eb;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #3b82f6;
  --color-brand-content: #3b82f6;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  --color-brand-primary: #3b82f6;
  --color-brand-content: #3b82f6;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">ApexRL 0.0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">ApexRL 0.0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/first_agent.html">Your First RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/custom_environment.html">Custom Environment Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/custom_network.html">Custom Network Architectures</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/environments.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/networks.html">Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/buffers.html">Buffers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/runners.html">Runners</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="modules.html">API</a><input aria-label="Toggle navigation of API" checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="apexrl.html">apexrl package</a><input aria-label="Toggle navigation of apexrl package" checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l3 has-children"><a class="reference internal" href="apexrl.agent.html">apexrl.agent package</a><input aria-label="Toggle navigation of apexrl.agent package" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="apexrl.agent.on_policy_runner.html">apexrl.agent.on_policy_runner module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="apexrl.algorithms.html">apexrl.algorithms package</a><input aria-label="Toggle navigation of apexrl.algorithms package" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="apexrl.algorithms.ppo.html">apexrl.algorithms.ppo package</a><input aria-label="Toggle navigation of apexrl.algorithms.ppo package" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="apexrl.algorithms.ppo.config.html">apexrl.algorithms.ppo.config module</a></li>
<li class="toctree-l5"><a class="reference internal" href="apexrl.algorithms.ppo.ppo.html">apexrl.algorithms.ppo.ppo module</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="apexrl.buffer.html">apexrl.buffer package</a><input aria-label="Toggle navigation of apexrl.buffer package" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="apexrl.buffer.distillation_buffer.html">apexrl.buffer.distillation_buffer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="apexrl.buffer.replay_buffer.html">apexrl.buffer.replay_buffer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="apexrl.buffer.rollout_buffer.html">apexrl.buffer.rollout_buffer module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="apexrl.envs.html">apexrl.envs package</a><input aria-label="Toggle navigation of apexrl.envs package" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="apexrl.envs.gym_wrapper.html">apexrl.envs.gym_wrapper module</a></li>
<li class="toctree-l4"><a class="reference internal" href="apexrl.envs.vecenv.html">apexrl.envs.vecenv module</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="apexrl.models.html">apexrl.models package</a><input aria-label="Toggle navigation of apexrl.models package" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="apexrl.models.dynamics.html">apexrl.models.dynamics package</a></li>
<li class="toctree-l4"><a class="reference internal" href="apexrl.models.base.html">apexrl.models.base module</a></li>
<li class="toctree-l4"><a class="reference internal" href="apexrl.models.mlp.html">apexrl.models.mlp module</a></li>
</ul>
</li>
<li class="toctree-l3 current has-children current-page"><a class="current reference internal" href="#">apexrl.optimizers package</a><input aria-label="Toggle navigation of apexrl.optimizers package" checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="apexrl.optimizers.muon.html">apexrl.optimizers.muon module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="apexrl.utils.html">apexrl.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/API/apexrl.optimizers.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="apexrl-optimizers-package">
<h1>apexrl.optimizers package<a class="headerlink" href="#apexrl-optimizers-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="apexrl.optimizers.muon.html">apexrl.optimizers.muon module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#id5">}</a></li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.Muon"><code class="docutils literal notranslate"><span class="pre">Muon</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.Muon.step"><code class="docutils literal notranslate"><span class="pre">Muon.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.MuonWithAuxAdam"><code class="docutils literal notranslate"><span class="pre">MuonWithAuxAdam</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.MuonWithAuxAdam.step"><code class="docutils literal notranslate"><span class="pre">MuonWithAuxAdam.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.SingleDeviceMuon"><code class="docutils literal notranslate"><span class="pre">SingleDeviceMuon</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.SingleDeviceMuon.step"><code class="docutils literal notranslate"><span class="pre">SingleDeviceMuon.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.SingleDeviceMuonWithAuxAdam"><code class="docutils literal notranslate"><span class="pre">SingleDeviceMuonWithAuxAdam</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.SingleDeviceMuonWithAuxAdam.step"><code class="docutils literal notranslate"><span class="pre">SingleDeviceMuonWithAuxAdam.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.adam_update"><code class="docutils literal notranslate"><span class="pre">adam_update()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.muon_update"><code class="docutils literal notranslate"><span class="pre">muon_update()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="apexrl.optimizers.muon.html#apexrl.optimizers.muon.zeropower_via_newtonschulz5"><code class="docutils literal notranslate"><span class="pre">zeropower_via_newtonschulz5()</span></code></a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="module-apexrl.optimizers">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-apexrl.optimizers" title="Link to this heading">¶</a></h2>
<p>Custom optimizers for reinforcement learning.</p>
<p>This module provides optimized implementations of various optimizers
including Adam, AdamW, and Muon optimizers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="apexrl.optimizers.Adam">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">apexrl.optimizers.</span></span><span class="sig-name descname"><span class="pre">Adam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.9,</span> <span class="pre">0.999)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">foreach</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">capturable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">differentiable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fused</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoupled_weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/optim/adam.html#Adam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apexrl.optimizers.Adam" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a></p>
<p>Implements Adam algorithm.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\begin{aligned}
     &amp;\rule{110mm}{0.4pt}                                                                 \\
     &amp;\textbf{input}      : \gamma \text{ (lr)}, \beta_1, \beta_2
         \text{ (betas)},\theta_0 \text{ (params)},f(\theta) \text{ (objective)}          \\
     &amp;\hspace{13mm}      \lambda \text{ (weight decay)},  \: \textit{amsgrad},
         \:\textit{maximize},  \: \epsilon \text{ (epsilon)}                              \\
     &amp;\textbf{initialize} :  m_0 \leftarrow 0 \text{ ( first moment)},
         v_0\leftarrow 0 \text{ (second moment)},\: v_0^{max}\leftarrow 0          \\[-1.ex]
     &amp;\rule{110mm}{0.4pt}                                                                 \\
     &amp;\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\\end{split}\\\begin{split}     &amp;\hspace{5mm}\textbf{if} \: \textit{maximize}:                                       \\
     &amp;\hspace{10mm}g_t           \leftarrow   -\nabla_{\theta} f_t (\theta_{t-1})         \\
     &amp;\hspace{5mm}\textbf{else}                                                           \\
     &amp;\hspace{10mm}g_t           \leftarrow   \nabla_{\theta} f_t (\theta_{t-1})          \\
     &amp;\hspace{5mm}\textbf{if} \: \lambda \neq 0                                           \\
     &amp;\hspace{10mm} g_t \leftarrow g_t + \lambda  \theta_{t-1}                            \\
     &amp;\hspace{5mm}m_t           \leftarrow   \beta_1 m_{t-1} + (1 - \beta_1) g_t          \\
     &amp;\hspace{5mm}v_t           \leftarrow   \beta_2 v_{t-1} + (1-\beta_2) g^2_t          \\
     &amp;\hspace{5mm}\widehat{m_t} \leftarrow   m_t/\big(1-\beta_1^t \big)                   \\
     &amp;\hspace{5mm}\textbf{if} \: amsgrad                                                  \\
     &amp;\hspace{10mm} v_t^{max} \leftarrow \mathrm{max}(v_{t-1}^{max},v_t)                  \\
     &amp;\hspace{10mm}\widehat{v_t} \leftarrow v_t^{max}/\big(1-\beta_2^t \big)              \\
     &amp;\hspace{5mm}\textbf{else}                                                           \\
     &amp;\hspace{10mm}\widehat{v_t} \leftarrow   v_t/\big(1-\beta_2^t \big)                  \\
     &amp;\hspace{5mm}\theta_t \leftarrow \theta_{t-1} - \gamma \widehat{m_t}/
         \big(\sqrt{\widehat{v_t}} + \epsilon \big)                                       \\
     &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]
     &amp;\bf{return} \:  \theta_t                                                     \\[-1.ex]
     &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]
\end{aligned}\end{split}\end{aligned}\end{align} \]</div>
</div>
<p>For further details regarding the algorithm we refer to <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>iterable</em>) – iterable of parameters or named_parameters to optimize
or iterable of dicts defining parameter groups. When using named_parameters,
all parameters in all groups should be named</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>, </em><em>optional</em>) – learning rate (default: 1e-3). A tensor LR
is not yet supported for all our implementations. Please use a float
LR if you are not also specifying fused=True or capturable=True.</p></li>
<li><p><strong>betas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>]</em><em>, </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>optional</em>) – coefficients used for computing running averages of gradient and
its square. If a tensor is provided, must be 1-element. (default: (0.9, 0.999))</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – term added to the denominator to improve
numerical stability (default: 1e-8)</p></li>
<li><p><strong>weight_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – weight decay (L2 penalty) (default: 0)</p></li>
<li><p><strong>decoupled_weight_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, this optimizer is
equivalent to AdamW and the algorithm will not accumulate weight
decay in the momentum nor variance. (default: False)</p></li>
<li><p><strong>amsgrad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to use the AMSGrad variant of this
algorithm from the paper <a class="reference external" href="https://openreview.net/forum?id=ryQu7f-RZ">On the Convergence of Adam and Beyond</a>
(default: False)</p></li>
<li><p><strong>foreach</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether foreach implementation of optimizer
is used. If unspecified by the user (so foreach is None), we will try to use
foreach over the for-loop implementation on CUDA, since it is usually
significantly more performant. Note that the foreach implementation uses
~ sizeof(params) more peak memory than the for-loop version due to the intermediates
being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer
parameters through the optimizer at a time or switch this flag to False (default: None)</p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – maximize the objective with respect to the
params, instead of minimizing (default: False)</p></li>
<li><p><strong>capturable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether this instance is safe to
capture in a graph, whether for CUDA graphs or for torch.compile support.
Tensors are only capturable when on supported <a class="reference external" href="https://docs.pytorch.org/docs/stable/torch.html#accelerators" title="(in PyTorch v2.10)"><span class="xref std std-ref">accelerators</span></a>.
Passing True can impair ungraphed performance, so if you don’t intend to graph
capture this instance, leave it False (default: False)</p></li>
<li><p><strong>differentiable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether autograd should
occur through the optimizer step in training. Otherwise, the step()
function runs in a torch.no_grad() context. Setting to True can impair
performance, so leave it False if you don’t intend to run autograd
through this instance (default: False)</p></li>
<li><p><strong>fused</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether the fused implementation is used.
Currently, <cite>torch.float64</cite>, <cite>torch.float32</cite>, <cite>torch.float16</cite>, and <cite>torch.bfloat16</cite>
are supported. (default: None)</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The foreach and fused implementations are typically faster than the for-loop,
single-tensor implementation, with fused being theoretically fastest with both
vertical and horizontal fusion. As such, if the user has not specified either
flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach
implementation when the tensors are all on CUDA. Why not fused? Since the fused
implementation is relatively new, we want to give it sufficient bake-in time.
To specify fused, pass True for fused. To force running the for-loop
implementation, pass False for either foreach or fused.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A prototype implementation of Adam and AdamW for MPS supports <cite>torch.float32</cite> and <cite>torch.float16</cite>.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="apexrl.optimizers.Adam.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/optim/adam.html#Adam.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apexrl.optimizers.Adam.step" title="Link to this definition">¶</a></dt>
<dd><p>Perform a single optimization step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>closure</strong> (<em>Callable</em><em>, </em><em>optional</em>) – A closure that reevaluates the model
and returns the loss.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="apexrl.optimizers.AdamW">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">apexrl.optimizers.</span></span><span class="sig-name descname"><span class="pre">AdamW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">betas</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.9,</span> <span class="pre">0.999)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">amsgrad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">maximize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">foreach</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">capturable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">differentiable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fused</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/optim/adamw.html#AdamW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apexrl.optimizers.AdamW" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#apexrl.optimizers.Adam" title="torch.optim.adam.Adam"><code class="xref py py-class docutils literal notranslate"><span class="pre">Adam</span></code></a></p>
<p>Implements AdamW algorithm, where weight decay does not accumulate in the momentum nor variance.</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\begin{split}\begin{aligned}
     &amp;\rule{110mm}{0.4pt}                                                                 \\
     &amp;\textbf{input}      : \gamma \text{(lr)}, \: \beta_1, \beta_2
         \text{(betas)}, \: \theta_0 \text{(params)}, \: f(\theta) \text{(objective)},
         \: \epsilon \text{ (epsilon)}                                                    \\
     &amp;\hspace{13mm}      \lambda \text{(weight decay)},  \: \textit{amsgrad},
         \: \textit{maximize}                                                             \\
     &amp;\textbf{initialize} : m_0 \leftarrow 0 \text{ (first moment)}, v_0 \leftarrow 0
         \text{ ( second moment)}, \: v_0^{max}\leftarrow 0                        \\[-1.ex]
     &amp;\rule{110mm}{0.4pt}                                                                 \\
     &amp;\textbf{for} \: t=1 \: \textbf{to} \: \ldots \: \textbf{do}                         \\\end{split}\\\begin{split}     &amp;\hspace{5mm}\textbf{if} \: \textit{maximize}:                                       \\
     &amp;\hspace{10mm}g_t           \leftarrow   -\nabla_{\theta} f_t (\theta_{t-1})         \\
     &amp;\hspace{5mm}\textbf{else}                                                           \\
     &amp;\hspace{10mm}g_t           \leftarrow   \nabla_{\theta} f_t (\theta_{t-1})          \\
     &amp;\hspace{5mm} \theta_t \leftarrow \theta_{t-1} - \gamma \lambda \theta_{t-1}         \\
     &amp;\hspace{5mm}m_t           \leftarrow   \beta_1 m_{t-1} + (1 - \beta_1) g_t          \\
     &amp;\hspace{5mm}v_t           \leftarrow   \beta_2 v_{t-1} + (1-\beta_2) g^2_t          \\
     &amp;\hspace{5mm}\widehat{m_t} \leftarrow   m_t/\big(1-\beta_1^t \big)                   \\
     &amp;\hspace{5mm}\textbf{if} \: amsgrad                                                  \\
     &amp;\hspace{10mm} v_t^{max} \leftarrow \mathrm{max}(v_{t-1}^{max},v_t)                  \\
     &amp;\hspace{10mm}\widehat{v_t} \leftarrow v_t^{max}/\big(1-\beta_2^t \big)              \\
     &amp;\hspace{5mm}\textbf{else}                                                           \\
     &amp;\hspace{10mm}\widehat{v_t} \leftarrow   v_t/\big(1-\beta_2^t \big)                  \\
     &amp;\hspace{5mm}\theta_t \leftarrow \theta_t - \gamma \widehat{m_t}/
         \big(\sqrt{\widehat{v_t}} + \epsilon \big)                                       \\
     &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]
     &amp;\bf{return} \:  \theta_t                                                     \\[-1.ex]
     &amp;\rule{110mm}{0.4pt}                                                          \\[-1.ex]
\end{aligned}\end{split}\end{aligned}\end{align} \]</div>
</div>
<p>For further details regarding the algorithm we refer to <a class="reference external" href="https://arxiv.org/abs/1711.05101">Decoupled Weight Decay Regularization</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>iterable</em>) – iterable of parameters or named_parameters to optimize
or iterable of dicts defining parameter groups. When using named_parameters,
all parameters in all groups should be named</p></li>
<li><p><strong>lr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>, </em><em>optional</em>) – learning rate (default: 1e-3). A tensor LR
is not yet supported for all our implementations. Please use a float
LR if you are not also specifying fused=True or capturable=True.</p></li>
<li><p><strong>betas</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>]</em><em>, </em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>Tensor</em><em>]</em><em>]</em><em>, </em><em>optional</em>) – coefficients used for computing running averages of gradient and
its square. If a tensor is provided, must be 1-element. (default: (0.9, 0.999))</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – term added to the denominator to improve
numerical stability (default: 1e-8)</p></li>
<li><p><strong>weight_decay</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>, </em><em>optional</em>) – weight decay coefficient (default: 1e-2)</p></li>
<li><p><strong>amsgrad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to use the AMSGrad variant of this
algorithm from the paper <a class="reference external" href="https://openreview.net/forum?id=ryQu7f-RZ">On the Convergence of Adam and Beyond</a>
(default: False)</p></li>
<li><p><strong>maximize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – maximize the objective with respect to the
params, instead of minimizing (default: False)</p></li>
<li><p><strong>foreach</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether foreach implementation of optimizer
is used. If unspecified by the user (so foreach is None), we will try to use
foreach over the for-loop implementation on CUDA, since it is usually
significantly more performant. Note that the foreach implementation uses
~ sizeof(params) more peak memory than the for-loop version due to the intermediates
being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer
parameters through the optimizer at a time or switch this flag to False (default: None)</p></li>
<li><p><strong>capturable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether this instance is safe to
capture in a graph, whether for CUDA graphs or for torch.compile support.
Tensors are only capturable when on supported <a class="reference external" href="https://docs.pytorch.org/docs/stable/torch.html#accelerators" title="(in PyTorch v2.10)"><span class="xref std std-ref">accelerators</span></a>.
Passing True can impair ungraphed performance, so if you don’t intend to graph
capture this instance, leave it False (default: False)</p></li>
<li><p><strong>differentiable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether autograd should
occur through the optimizer step in training. Otherwise, the step()
function runs in a torch.no_grad() context. Setting to True can impair
performance, so leave it False if you don’t intend to run autograd
through this instance (default: False)</p></li>
<li><p><strong>fused</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – whether the fused implementation is used.
Currently, <cite>torch.float64</cite>, <cite>torch.float32</cite>, <cite>torch.float16</cite>, and <cite>torch.bfloat16</cite>
are supported. (default: None)</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The foreach and fused implementations are typically faster than the for-loop,
single-tensor implementation, with fused being theoretically fastest with both
vertical and horizontal fusion. As such, if the user has not specified either
flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach
implementation when the tensors are all on CUDA. Why not fused? Since the fused
implementation is relatively new, we want to give it sufficient bake-in time.
To specify fused, pass True for fused. To force running the for-loop
implementation, pass False for either foreach or fused.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A prototype implementation of Adam and AdamW for MPS supports <cite>torch.float32</cite> and <cite>torch.float16</cite>.</p>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="apexrl.optimizers.Muon">
<span class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></span><span class="sig-prename descclassname"><span class="pre">apexrl.optimizers.</span></span><span class="sig-name descname"><span class="pre">Muon</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/apexrl/optimizers/muon.html#Muon"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apexrl.optimizers.Muon" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Optimizer</span></code></a></p>
<p>Muon - MomentUm Orthogonalized by Newton-schulz</p>
<p><a class="reference external" href="https://kellerjordan.github.io/posts/muon/">https://kellerjordan.github.io/posts/muon/</a></p>
<p>Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
processing step, in which each 2D parameter’s update is replaced with the nearest orthogonal
matrix. For efficient orthogonalization we use a Newton-Schulz iteration, which has the
advantage that it can be stably run in bfloat16 on the GPU.</p>
<p>Muon should only be used for hidden weight layers. The input embedding, final output layer,
and any internal gains or biases should be optimized using a standard method such as AdamW.
Hidden convolutional weights can be trained using Muon by viewing them as 2D and then
collapsing their last 3 dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr</strong> – The learning rate, in units of spectral norm per update.</p></li>
<li><p><strong>weight_decay</strong> – The AdamW-style weight decay.</p></li>
<li><p><strong>momentum</strong> – The momentum. A value of 0.95 here is usually fine.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="apexrl.optimizers.Muon.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/apexrl/optimizers/muon.html#Muon.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#apexrl.optimizers.Muon.step" title="Link to this definition">¶</a></dt>
<dd><p>Perform a single optimization step to update parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>closure</strong> (<em>Callable</em>) – A closure that reevaluates the model and
returns the loss. Optional for most optimizers.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="apexrl.optimizers.muon.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">apexrl.optimizers.muon module</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="apexrl.models.mlp.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">apexrl.models.mlp module</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2026, Atticlmr
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/Atticlmr/Apex_rl" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">apexrl.optimizers package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-apexrl.optimizers">Module contents</a><ul>
<li><a class="reference internal" href="#apexrl.optimizers.Adam"><code class="docutils literal notranslate"><span class="pre">Adam</span></code></a><ul>
<li><a class="reference internal" href="#apexrl.optimizers.Adam.step"><code class="docutils literal notranslate"><span class="pre">Adam.step()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#apexrl.optimizers.AdamW"><code class="docutils literal notranslate"><span class="pre">AdamW</span></code></a></li>
<li><a class="reference internal" href="#apexrl.optimizers.Muon"><code class="docutils literal notranslate"><span class="pre">Muon</span></code></a><ul>
<li><a class="reference internal" href="#apexrl.optimizers.Muon.step"><code class="docutils literal notranslate"><span class="pre">Muon.step()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=f539c95a"></script>
    <script src="../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
    </body>
</html>