<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>apexrl.algorithms.ppo.ppo &#8212; ApexRL 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=27fed22d" />
    <script src="../../../../_static/documentation_options.js?v=d45e8c67"></script>
    <script src="../../../../_static/doctools.js?v=fd6eb6e6"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=6ffebe34"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for apexrl.algorithms.ppo.ppo</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2026 GitHub@Apex_rl Developer</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;PPO (Proximal Policy Optimization) algorithm implementation.</span>

<span class="sd">Supports custom Actor and Critic networks defined by users.</span>

<span class="sd">References:</span>
<span class="sd">    - Original paper: https://arxiv.org/abs/1707.06347</span>
<span class="sd">    - rsl_rl: https://github.com/leggedrobotics/rsl_rl</span>
<span class="sd">    - stable-baselines3: https://github.com/DLR-RM/stable-baselines3</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">collections</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Deque</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.tensorboard</span><span class="w"> </span><span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="kn">import</span> <span class="n">spaces</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">apexrl.algorithms.ppo.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">PPOConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">apexrl.buffer.rollout_buffer</span><span class="w"> </span><span class="kn">import</span> <span class="n">RolloutBuffer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">apexrl.envs.vecenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">VecEnv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">apexrl.models.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">Actor</span><span class="p">,</span> <span class="n">ContinuousActor</span><span class="p">,</span> <span class="n">Critic</span><span class="p">,</span> <span class="n">DiscreteActor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">apexrl.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_optimizer</span>


<div class="viewcode-block" id="PPO">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">PPO</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;PPO algorithm for vectorized environments with custom networks.</span>

<span class="sd">    Users provide custom Actor and Critic classes, and PPO handles the</span>
<span class="sd">    training loop, advantage computation, and optimization.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; from apexrl.algorithms.ppo import PPO, PPOConfig</span>
<span class="sd">        &gt;&gt;&gt; from apexrl.envs.vecenv import DummyVecEnv</span>
<span class="sd">        &gt;&gt;&gt; from apexrl.models.mlp import MLPActor, MLPCritic</span>
<span class="sd">        &gt;&gt;&gt; from gymnasium import spaces</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create environment</span>
<span class="sd">        &gt;&gt;&gt; env = DummyVecEnv(num_envs=4096, num_obs=48, num_actions=12)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define observation and action spaces</span>
<span class="sd">        &gt;&gt;&gt; obs_space = spaces.Box(low=-float(&#39;inf&#39;), high=float(&#39;inf&#39;), shape=(48,))</span>
<span class="sd">        &gt;&gt;&gt; action_space = spaces.Box(low=-1, high=1, shape=(12,))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Configure PPO</span>
<span class="sd">        &gt;&gt;&gt; cfg = PPOConfig(num_steps=24, learning_rate=3e-4)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create agent with custom networks</span>
<span class="sd">        &gt;&gt;&gt; agent = PPO(</span>
<span class="sd">        ...     env=env,</span>
<span class="sd">        ...     cfg=cfg,</span>
<span class="sd">        ...     actor_class=MLPActor,</span>
<span class="sd">        ...     critic_class=MLPCritic,</span>
<span class="sd">        ...     obs_space=obs_space,</span>
<span class="sd">        ...     action_space=action_space,</span>
<span class="sd">        ...     actor_cfg={&quot;hidden_dims&quot;: [256, 256, 256]},</span>
<span class="sd">        ...     critic_cfg={&quot;hidden_dims&quot;: [256, 256, 256]},</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Train</span>
<span class="sd">        &gt;&gt;&gt; agent.learn(total_timesteps=10_000_000)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">env</span><span class="p">:</span> <span class="n">VecEnv</span><span class="p">,</span>
        <span class="n">cfg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PPOConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">actor_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Actor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">critic_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">Critic</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">obs_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">actor_cfg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">critic_cfg</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">actor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Actor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">critic</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Critic</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize PPO algorithm.</span>

<span class="sd">        Args:</span>
<span class="sd">            env: Vectorized environment implementing VecEnv interface.</span>
<span class="sd">            cfg: PPO configuration. Uses defaults if None.</span>
<span class="sd">            actor_class: Actor class to instantiate (e.g., MLPActor, CNNActor).</span>
<span class="sd">            critic_class: Critic class to instantiate (e.g., MLPCritic, CNNCritic).</span>
<span class="sd">            obs_space: Observation space (gymnasium.Space). Required if not providing</span>
<span class="sd">                pre-instantiated actor/critic.</span>
<span class="sd">            action_space: Action space (gymnasium.Space). Required if not providing</span>
<span class="sd">                pre-instantiated actor/critic.</span>
<span class="sd">            actor_cfg: Configuration dict passed to actor_class constructor.</span>
<span class="sd">            critic_cfg: Configuration dict passed to critic_class constructor.</span>
<span class="sd">            actor: Pre-instantiated actor network (alternative to actor_class).</span>
<span class="sd">            critic: Pre-instantiated critic network (alternative to critic_class).</span>
<span class="sd">            log_dir: Directory for TensorBoard logs.</span>
<span class="sd">            device: Device for training. Auto-detects if None.</span>

<span class="sd">        Note:</span>
<span class="sd">            Either provide (actor_class, critic_class, obs_space, action_space) OR</span>
<span class="sd">            provide (actor, critic) directly.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span> <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">PPOConfig</span><span class="p">()</span>

        <span class="c1"># Device setup</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
                    <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="c1"># Get environment info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">num_envs</span>

        <span class="c1"># Initialize actor and critic</span>
        <span class="k">if</span> <span class="n">actor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">critic</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Use pre-instantiated networks</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">actor</span> <span class="o">=</span> <span class="n">actor</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic</span> <span class="o">=</span> <span class="n">critic</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">obs_space</span> <span class="o">=</span> <span class="n">obs_space</span> <span class="ow">or</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="s2">&quot;obs_space&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="s2">&quot;action_space&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">actor_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">critic_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Instantiate from classes</span>
            <span class="k">if</span> <span class="n">obs_space</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">action_space</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;obs_space and action_space are required when using actor_class/critic_class&quot;</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">obs_space</span> <span class="o">=</span> <span class="n">obs_space</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>

            <span class="c1"># Create actor</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">actor</span> <span class="o">=</span> <span class="n">actor_class</span><span class="p">(</span>
                <span class="n">obs_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
                <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
                <span class="n">cfg</span><span class="o">=</span><span class="n">actor_cfg</span> <span class="ow">or</span> <span class="p">{},</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Create critic (may use privileged obs if asymmetric)</span>
            <span class="n">critic_obs_space</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">getattr</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="s2">&quot;privileged_obs_space&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="n">obs_space</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_asymmetric</span>
                <span class="k">else</span> <span class="n">obs_space</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">critic</span> <span class="o">=</span> <span class="n">critic_class</span><span class="p">(</span>
                <span class="n">obs_space</span><span class="o">=</span><span class="n">critic_obs_space</span><span class="p">,</span>
                <span class="n">cfg</span><span class="o">=</span><span class="n">critic_cfg</span> <span class="ow">or</span> <span class="p">{},</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Must provide either (actor, critic) OR &quot;</span>
                <span class="s2">&quot;(actor_class, critic_class, obs_space, action_space)&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Verify actor type</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">,</span> <span class="p">(</span><span class="n">ContinuousActor</span><span class="p">,</span> <span class="n">DiscreteActor</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;PPO currently only supports ContinuousActor or DiscreteActor, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Get action dimension</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_dim</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Discrete actions are single integers</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Action space </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span><span class="si">}</span><span class="s2"> not supported&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Initialize optimizer</span>
        <span class="n">optimizer_cls</span> <span class="o">=</span> <span class="n">get_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_policy_optimizer</span><span class="p">:</span>
            <span class="c1"># Separate optimizers for policy and value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy_learning_rate</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">value_learning_rate</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Joint optimizer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span>
                <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Initialize rollout buffer</span>
        <span class="c1"># Infer obs shape from obs_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_obs_shape</span><span class="p">(</span><span class="n">obs_space</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span> <span class="o">=</span> <span class="n">RolloutBuffer</span><span class="p">(</span>
            <span class="n">num_envs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">,</span>
            <span class="n">num_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_steps</span><span class="p">,</span>
            <span class="n">obs_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">obs_shape</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">num_privileged_obs</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="s2">&quot;num_privileged_obs&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_asymmetric</span>
            <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">log_dir</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Metrics storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Loss history vs iteration (fixed size deque to prevent memory leak)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Deque</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_obs_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get observation shape from space.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">obs_space</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Try to infer from env</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="p">,</span> <span class="s2">&quot;num_obs&quot;</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">num_obs</span><span class="p">,)</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>  <span class="c1"># Fallback</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_space</span><span class="p">,</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">obs_space</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Observation space </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obs_space</span><span class="p">)</span><span class="si">}</span><span class="s2"> not supported&quot;</span>
            <span class="p">)</span>

<div class="viewcode-block" id="PPO.collect_rollout">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.collect_rollout">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">collect_rollout</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">extras_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Collect a rollout from the environment.</span>

<span class="sd">        Args:</span>
<span class="sd">            extras_callback: Optional callback function called after each step with</span>
<span class="sd">                (extras, dones, true_dones, episode_rewards) to process environment</span>
<span class="sd">                extras such as reward components and custom metrics.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of rollout statistics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="c1"># Get initial observations</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">get_observations</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">):</span>  <span class="c1"># TensorDict</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">episode_rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">episode_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">completed_episodes</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_steps</span><span class="p">):</span>
            <span class="c1"># Get privileged obs if using asymmetric critic</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_asymmetric</span><span class="p">:</span>
                <span class="n">privileged_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">get_privileged_observations</span><span class="p">()</span>
                <span class="n">privileged_obs</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">privileged_obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">privileged_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="kc">None</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">privileged_obs</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Sample actions</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">actions</span><span class="p">,</span> <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span>
                    <span class="n">privileged_obs</span> <span class="k">if</span> <span class="n">privileged_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">obs</span>
                <span class="p">)</span>

            <span class="c1"># Step environment</span>
            <span class="n">next_obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">extras</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">):</span>  <span class="c1"># TensorDict</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="n">dones</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Track episode stats</span>
            <span class="n">episode_rewards</span> <span class="o">+=</span> <span class="n">rewards</span>
            <span class="n">episode_lengths</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Check for timeouts</span>
            <span class="n">time_outs</span> <span class="o">=</span> <span class="n">extras</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;time_outs&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">dones</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time_outs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">time_outs</span> <span class="o">=</span> <span class="n">time_outs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">true_dones</span> <span class="o">=</span> <span class="n">dones</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">time_outs</span>

            <span class="c1"># Call extras callback if provided (for reward components logging)</span>
            <span class="k">if</span> <span class="n">extras_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">extras_callback</span><span class="p">(</span><span class="n">extras</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">true_dones</span><span class="p">,</span> <span class="n">episode_rewards</span><span class="p">)</span>

            <span class="c1"># Log completed episodes</span>
            <span class="k">if</span> <span class="n">true_dones</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">completed_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">true_dones</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">completed_indices</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">episode_lengths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">episode_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="n">completed_episodes</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Reset episode tracking for completed envs</span>
                <span class="n">episode_rewards</span> <span class="o">=</span> <span class="n">episode_rewards</span> <span class="o">*</span> <span class="p">(</span><span class="o">~</span><span class="n">true_dones</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="n">episode_lengths</span> <span class="o">=</span> <span class="n">episode_lengths</span> <span class="o">*</span> <span class="p">(</span><span class="o">~</span><span class="n">true_dones</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

            <span class="c1"># Store transition</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                <span class="n">observations</span><span class="o">=</span><span class="n">obs</span><span class="p">,</span>
                <span class="n">privileged_observations</span><span class="o">=</span><span class="n">privileged_obs</span><span class="p">,</span>
                <span class="n">actions</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span>
                <span class="n">rewards</span><span class="o">=</span><span class="n">rewards</span><span class="p">,</span>
                <span class="n">dones</span><span class="o">=</span><span class="n">dones</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                <span class="n">log_probs</span><span class="o">=</span><span class="n">log_probs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">obs</span> <span class="o">=</span> <span class="n">next_obs</span>

        <span class="c1"># Compute returns and advantages</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Get privileged observations (avoid duplicate calls)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">use_asymmetric</span><span class="p">:</span>
                <span class="n">last_privileged_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">get_privileged_observations</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">last_privileged_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">last_privileged_obs</span> <span class="o">=</span> <span class="n">last_privileged_obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">last_privileged_obs</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">last_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span>
                <span class="n">last_privileged_obs</span> <span class="k">if</span> <span class="n">last_privileged_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">obs</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">compute_returns_and_advantages</span><span class="p">(</span>
            <span class="n">last_values</span><span class="o">=</span><span class="n">last_values</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">gae_lambda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">gae_lambda</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Normalize advantages if enabled</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">normalize_advantages</span><span class="p">:</span>
            <span class="n">advantages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">advantages</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">advantages</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantages</span> <span class="o">-</span> <span class="n">advantages</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">advantages</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span>

        <span class="c1"># Return rollout stats</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;rollout/mean_reward&quot;</span><span class="p">:</span> <span class="n">rewards</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="s2">&quot;rollout/mean_value&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">completed_episodes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;rollout/mean_episode_reward&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_reward</span> <span class="o">/</span> <span class="n">completed_episodes</span>
            <span class="n">stats</span><span class="p">[</span><span class="s2">&quot;rollout/completed_episodes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">completed_episodes</span>

        <span class="k">return</span> <span class="n">stats</span></div>


<div class="viewcode-block" id="PPO.update">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.update">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update policy and value function using collected rollout data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary of training statistics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># Get all rollout data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">get_all_data</span><span class="p">()</span>
        <span class="n">observations</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;observations&quot;</span><span class="p">]</span>
        <span class="n">privileged_observations</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;privileged_observations&quot;</span><span class="p">]</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;actions&quot;</span><span class="p">]</span>
        <span class="n">old_log_probs</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;old_log_probs&quot;</span><span class="p">]</span>
        <span class="n">advantages</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;advantages&quot;</span><span class="p">]</span>
        <span class="n">returns</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;returns&quot;</span><span class="p">]</span>
        <span class="n">old_values</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;values&quot;</span><span class="p">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">observations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">minibatch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">get_minibatch_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>

        <span class="c1"># Training metrics</span>
        <span class="n">total_policy_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_value_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_entropy_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_approx_kl</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_clip_fraction</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">num_updates</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Update for multiple epochs</span>
        <span class="n">early_stopped</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="c1"># Shuffle indices</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Minibatch updates</span>
            <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">):</span>
                <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

                <span class="n">mb_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>

                <span class="n">mb_obs</span> <span class="o">=</span> <span class="n">observations</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                <span class="n">mb_privileged_obs</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">privileged_observations</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">privileged_observations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="kc">None</span>
                <span class="p">)</span>
                <span class="n">mb_actions</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                <span class="n">mb_old_log_probs</span> <span class="o">=</span> <span class="n">old_log_probs</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                <span class="n">mb_advantages</span> <span class="o">=</span> <span class="n">advantages</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                <span class="n">mb_returns</span> <span class="o">=</span> <span class="n">returns</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>
                <span class="n">mb_old_values</span> <span class="o">=</span> <span class="n">old_values</span><span class="p">[</span><span class="n">mb_indices</span><span class="p">]</span>

                <span class="c1"># Evaluate actions</span>
                <span class="n">log_probs</span><span class="p">,</span> <span class="n">entropy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">mb_obs</span><span class="p">,</span> <span class="n">mb_actions</span><span class="p">)</span>
                <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span>
                    <span class="n">mb_privileged_obs</span> <span class="k">if</span> <span class="n">mb_privileged_obs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">mb_obs</span>
                <span class="p">)</span>

                <span class="c1"># Policy loss (PPO clip)</span>
                <span class="n">ratio</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_probs</span> <span class="o">-</span> <span class="n">mb_old_log_probs</span><span class="p">)</span>
                <span class="n">surr1</span> <span class="o">=</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">mb_advantages</span>
                <span class="n">surr2</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range</span><span class="p">)</span>
                    <span class="o">*</span> <span class="n">mb_advantages</span>
                <span class="p">)</span>
                <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">surr1</span><span class="p">,</span> <span class="n">surr2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                <span class="c1"># Value loss</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range_vf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># Clip value function</span>
                    <span class="n">value_pred_clipped</span> <span class="o">=</span> <span class="n">mb_old_values</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                        <span class="n">values</span> <span class="o">-</span> <span class="n">mb_old_values</span><span class="p">,</span>
                        <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range_vf</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range_vf</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">value_loss1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mb_returns</span><span class="p">)</span>
                    <span class="n">value_loss2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">value_pred_clipped</span><span class="p">,</span> <span class="n">mb_returns</span><span class="p">)</span>
                    <span class="n">value_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">value_loss1</span><span class="p">,</span> <span class="n">value_loss2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">mb_returns</span><span class="p">)</span>

                <span class="c1"># Entropy loss</span>
                <span class="n">entropy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">entropy</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

                <span class="c1"># Total loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">policy_loss</span>
                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">vf_coef</span> <span class="o">*</span> <span class="n">value_loss</span>
                    <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">ent_coef</span> <span class="o">*</span> <span class="n">entropy_loss</span>
                <span class="p">)</span>

                <span class="c1"># Optimization step with gradient norm tracking (before clipping)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="c1"># Compute unclipped gradient norm for logging</span>
                    <span class="n">actor_grad_norm_unclipped</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">critic_grad_norm_unclipped</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># Apply actual gradient clipping</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_grad_norm</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Separate optimizers</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="c1"># Compute unclipped gradient norm for logging</span>
                    <span class="n">actor_grad_norm_unclipped</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">critic_grad_norm_unclipped</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># Apply actual gradient clipping</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_grad_norm</span>
                    <span class="p">)</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_grad_norm</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># Metrics</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="c1"># Clamp ratio for numerical stability in KL computation</span>
                    <span class="n">ratio_clamped</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">10.0</span><span class="p">)</span>
                    <span class="n">approx_kl</span> <span class="o">=</span> <span class="p">((</span><span class="n">ratio_clamped</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ratio_clamped</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                    <span class="n">clip_fraction</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="p">((</span><span class="n">ratio</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">clip_range</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                    <span class="p">)</span>

                <span class="n">total_policy_loss</span> <span class="o">+=</span> <span class="n">policy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total_value_loss</span> <span class="o">+=</span> <span class="n">value_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total_entropy_loss</span> <span class="o">+=</span> <span class="n">entropy_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total_approx_kl</span> <span class="o">+=</span> <span class="n">approx_kl</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total_clip_fraction</span> <span class="o">+=</span> <span class="n">clip_fraction</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">num_updates</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1"># Accumulate gradient norms</span>
                <span class="k">if</span> <span class="n">num_updates</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">total_actor_grad_norm</span> <span class="o">=</span> <span class="n">actor_grad_norm_unclipped</span>
                    <span class="n">total_critic_grad_norm</span> <span class="o">=</span> <span class="n">critic_grad_norm_unclipped</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">total_actor_grad_norm</span> <span class="o">+=</span> <span class="n">actor_grad_norm_unclipped</span>
                    <span class="n">total_critic_grad_norm</span> <span class="o">+=</span> <span class="n">critic_grad_norm_unclipped</span>

                <span class="c1"># Early stopping on KL divergence</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">target_kl</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="ow">and</span> <span class="n">approx_kl</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">target_kl</span>
                <span class="p">):</span>
                    <span class="n">early_stopped</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>

            <span class="k">if</span> <span class="n">early_stopped</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="c1"># Average metrics</span>
        <span class="n">avg_policy_loss</span> <span class="o">=</span> <span class="n">total_policy_loss</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_value_loss</span> <span class="o">=</span> <span class="n">total_value_loss</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_entropy_loss</span> <span class="o">=</span> <span class="n">total_entropy_loss</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_approx_kl</span> <span class="o">=</span> <span class="n">total_approx_kl</span> <span class="o">/</span> <span class="n">num_updates</span>
        <span class="n">avg_clip_fraction</span> <span class="o">=</span> <span class="n">total_clip_fraction</span> <span class="o">/</span> <span class="n">num_updates</span>

        <span class="c1"># Average gradient norms</span>
        <span class="n">avg_actor_grad_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_actor_grad_norm</span> <span class="o">/</span> <span class="n">num_updates</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">avg_critic_grad_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_critic_grad_norm</span> <span class="o">/</span> <span class="n">num_updates</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">avg_total_grad_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">avg_actor_grad_norm</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">avg_critic_grad_norm</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;train/policy_loss&quot;</span><span class="p">:</span> <span class="n">avg_policy_loss</span><span class="p">,</span>
            <span class="s2">&quot;train/value_loss&quot;</span><span class="p">:</span> <span class="n">avg_value_loss</span><span class="p">,</span>
            <span class="s2">&quot;train/entropy_loss&quot;</span><span class="p">:</span> <span class="n">avg_entropy_loss</span><span class="p">,</span>
            <span class="s2">&quot;train/approx_kl&quot;</span><span class="p">:</span> <span class="n">avg_approx_kl</span><span class="p">,</span>
            <span class="s2">&quot;train/clip_fraction&quot;</span><span class="p">:</span> <span class="n">avg_clip_fraction</span><span class="p">,</span>
            <span class="s2">&quot;train/learning_rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_current_lr</span><span class="p">(),</span>
            <span class="s2">&quot;train/actor_grad_norm&quot;</span><span class="p">:</span> <span class="n">avg_actor_grad_norm</span><span class="p">,</span>
            <span class="s2">&quot;train/critic_grad_norm&quot;</span><span class="p">:</span> <span class="n">avg_critic_grad_norm</span><span class="p">,</span>
            <span class="s2">&quot;train/total_grad_norm&quot;</span><span class="p">:</span> <span class="n">avg_total_grad_norm</span><span class="p">,</span>
            <span class="s2">&quot;train/early_stopped&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">early_stopped</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">stats</span></div>


<div class="viewcode-block" id="PPO.get_current_lr">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.get_current_lr">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_current_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get current learning rate.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span></div>


<div class="viewcode-block" id="PPO.adjust_learning_rate">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.adjust_learning_rate">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">adjust_learning_rate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">current_iteration</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">total_iterations</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adjust learning rate based on schedule.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate_schedule</span> <span class="o">==</span> <span class="s2">&quot;constant&quot;</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate_schedule</span> <span class="o">==</span> <span class="s2">&quot;linear&quot;</span><span class="p">:</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="n">current_iteration</span> <span class="o">/</span> <span class="n">total_iterations</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">progress</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate_schedule</span> <span class="o">==</span> <span class="s2">&quot;adaptive&quot;</span><span class="p">:</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="n">current_iteration</span> <span class="o">/</span> <span class="n">total_iterations</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">min_learning_rate</span> <span class="o">+</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_learning_rate</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">min_learning_rate</span>
            <span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">progress</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Update optimizer learning rates</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                <span class="n">param_group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_lr</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                <span class="n">param_group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_lr</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">policy_learning_rate</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="p">)</span>
            <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                <span class="n">param_group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_lr</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">value_learning_rate</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">learning_rate</span>
                <span class="p">)</span></div>


<div class="viewcode-block" id="PPO.learn">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.learn">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">total_timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train the agent.</span>

<span class="sd">        Args:</span>
<span class="sd">            total_timesteps: Total number of timesteps to train for.</span>
<span class="sd">                Ignored if max_iterations is set in config.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Determine number of iterations</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_iterations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_iterations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">max_iterations</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">num_iterations</span><span class="si">}</span><span class="s2"> iterations (max_iterations from config)&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">total_timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_iterations</span> <span class="o">=</span> <span class="n">total_timesteps</span> <span class="o">//</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Training for </span><span class="si">{</span><span class="n">num_iterations</span><span class="si">}</span><span class="s2"> iterations (derived from </span><span class="si">{</span><span class="n">total_timesteps</span><span class="si">}</span><span class="s2"> timesteps)&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either total_timesteps or cfg.max_iterations must be set&quot;</span><span class="p">)</span>

        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Initialize history tracking for losses vs iteration (fixed size deque)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;iterations&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;policy_loss&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;value_loss&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;entropy_loss&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;approx_kl&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;clip_fraction&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;actor_grad_norm&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;critic_grad_norm&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
            <span class="s2">&quot;total_grad_norm&quot;</span><span class="p">:</span> <span class="n">collections</span><span class="o">.</span><span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history_maxlen</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="n">iteration</span>

            <span class="c1"># Collect rollout</span>
            <span class="n">rollout_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collect_rollout</span><span class="p">()</span>

            <span class="c1"># Update policy</span>
            <span class="n">update_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="c1"># Record loss history vs iteration (deque auto-manages size)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;iterations&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">iteration</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;policy_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">update_stats</span><span class="p">[</span><span class="s2">&quot;train/policy_loss&quot;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;value_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">update_stats</span><span class="p">[</span><span class="s2">&quot;train/value_loss&quot;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;entropy_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/entropy_loss&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;approx_kl&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/approx_kl&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;clip_fraction&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/clip_fraction&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;actor_grad_norm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/actor_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;critic_grad_norm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/critic_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="s2">&quot;total_grad_norm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/total_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Log additional detailed stats to tensorboard immediately</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># Log advantage and value distribution stats</span>
                <span class="n">advantages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">advantages</span>
                <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">values</span>
                <span class="n">returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rollout_buffer</span><span class="o">.</span><span class="n">returns</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;advantage/mean&quot;</span><span class="p">,</span> <span class="n">advantages</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;advantage/std&quot;</span><span class="p">,</span> <span class="n">advantages</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;advantage/min&quot;</span><span class="p">,</span> <span class="n">advantages</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;advantage/max&quot;</span><span class="p">,</span> <span class="n">advantages</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span>
                <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;value/mean&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;value/std&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;value/min&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;value/max&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;returns/mean&quot;</span><span class="p">,</span> <span class="n">returns</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;returns/std&quot;</span><span class="p">,</span> <span class="n">returns</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>

            <span class="c1"># Adjust learning rate</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">adjust_learning_rate</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">)</span>

            <span class="c1"># Logging</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="ow">and</span> <span class="n">iteration</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">fps</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">num_steps</span>
                    <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span>
                    <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">log_interval</span>
                    <span class="o">/</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;time/fps&quot;</span><span class="p">,</span> <span class="n">fps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;time/iterations&quot;</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span>
                <span class="p">)</span>

                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">rollout_stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">update_stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span><span class="p">)</span>

                <span class="c1"># Also log with iteration as x-axis for easier analysis</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/policy_loss&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="p">[</span><span class="s2">&quot;train/policy_loss&quot;</span><span class="p">],</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/value_loss&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="p">[</span><span class="s2">&quot;train/value_loss&quot;</span><span class="p">],</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/entropy_loss&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/entropy_loss&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/approx_kl&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/approx_kl&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/clip_fraction&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/clip_fraction&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/actor_grad_norm&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/actor_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/critic_grad_norm&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/critic_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;train_vs_iter/total_grad_norm&quot;</span><span class="p">,</span>
                    <span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;train/total_grad_norm&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                    <span class="n">iteration</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># Log episode stats</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span><span class="p">:</span>
                    <span class="n">mean_reward</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span><span class="p">)</span>
                    <span class="n">mean_length</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;episode/mean_reward&quot;</span><span class="p">,</span> <span class="n">mean_reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;episode/mean_length&quot;</span><span class="p">,</span> <span class="n">mean_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span>
                    <span class="p">)</span>
                    <span class="c1"># Also log with iteration</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;episode_vs_iter/mean_reward&quot;</span><span class="p">,</span> <span class="n">mean_reward</span><span class="p">,</span> <span class="n">iteration</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;episode_vs_iter/mean_length&quot;</span><span class="p">,</span> <span class="n">mean_length</span><span class="p">,</span> <span class="n">iteration</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">episode_rewards</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">episode_lengths</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_iterations</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Timesteps </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;FPS </span><span class="si">{</span><span class="n">fps</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Policy Loss </span><span class="si">{</span><span class="n">update_stats</span><span class="p">[</span><span class="s1">&#39;train/policy_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Value Loss </span><span class="si">{</span><span class="n">update_stats</span><span class="p">[</span><span class="s1">&#39;train/value_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Grad Norm </span><span class="si">{</span><span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;train/total_grad_norm&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;KL </span><span class="si">{</span><span class="n">update_stats</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;train/approx_kl&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Save checkpoint</span>
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;checkpoint_</span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">.pt&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="PPO.save">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.save">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model checkpoint.&quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;actor_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;critic_state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">),</span>
            <span class="s2">&quot;policy_optimizer_state_dict&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">),</span>
            <span class="s2">&quot;value_optimizer_state_dict&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">),</span>
            <span class="s2">&quot;iteration&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
            <span class="s2">&quot;total_timesteps&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span><span class="p">,</span>
            <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>


<div class="viewcode-block" id="PPO.load">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.load">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model checkpoint.&quot;&quot;&quot;</span>
        <span class="c1"># PyTorch 2.6+ changed weights_only default to True</span>
        <span class="c1"># We need to handle both old and new behavior</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="c1"># Older PyTorch versions don&#39;t have weights_only parameter</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;actor_state_dict&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;critic_state_dict&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">and</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span> <span class="ow">and</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;policy_optimizer_state_dict&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">policy_optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;policy_optimizer_state_dict&quot;</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span> <span class="ow">and</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;value_optimizer_state_dict&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;value_optimizer_state_dict&quot;</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;iteration&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_timesteps</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;total_timesteps&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="PPO.eval">
<a class="viewcode-back" href="../../../../API/apexrl.algorithms.ppo.ppo.html#apexrl.algorithms.PPO.eval">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_episodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the agent.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">episode_rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_envs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">episodes_completed</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="n">episodes_completed</span> <span class="o">&lt;</span> <span class="n">num_episodes</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">actions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">next_obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="s2">&quot;get&quot;</span><span class="p">):</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_obs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">dones</span> <span class="o">=</span> <span class="n">dones</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">current_rewards</span> <span class="o">+=</span> <span class="n">rewards</span>

            <span class="k">if</span> <span class="n">dones</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="n">done_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">dones</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">done_indices</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">episodes_completed</span> <span class="o">&lt;</span> <span class="n">num_episodes</span><span class="p">:</span>
                        <span class="n">episode_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_rewards</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                        <span class="n">episodes_completed</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">current_rewards</span> <span class="o">=</span> <span class="n">current_rewards</span> <span class="o">*</span> <span class="p">(</span><span class="o">~</span><span class="n">dones</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

            <span class="n">obs</span> <span class="o">=</span> <span class="n">next_obs</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;eval/mean_reward&quot;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">),</span>
            <span class="s2">&quot;eval/std_reward&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="nb">sum</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>
                    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">episode_rewards</span>
                <span class="p">)</span>
                <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span>
            <span class="s2">&quot;eval/min_reward&quot;</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">),</span>
            <span class="s2">&quot;eval/max_reward&quot;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">episode_rewards</span><span class="p">),</span>
        <span class="p">}</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">ApexRL</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  <li><a href="../../../apexrl.html">apexrl</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2026, Atticlmr.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 9.0.4</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>